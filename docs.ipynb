{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read csv to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>discounted_price</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>discount_percentage</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>about_product</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_content</th>\n",
       "      <th>img_link</th>\n",
       "      <th>product_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>B0873L7J6X</td>\n",
       "      <td>Infinity (JBL Glide 510, 72 Hrs Playtime with ...</td>\n",
       "      <td>Electronics|Headphones,Earbuds&amp;Accessories|Hea...</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>₹3,999</td>\n",
       "      <td>63%</td>\n",
       "      <td>4.2</td>\n",
       "      <td>42,775</td>\n",
       "      <td>72 Hours Playtime Under Optimum Audio Settings...</td>\n",
       "      <td>AGHTZ6M45GWLTAEPAMM6IEH2BXOA,AGVTW4CSK4PNN4WGW...</td>\n",
       "      <td>(sic),Harshit,Bharath N,Pulkit Malik,Akhtar An...</td>\n",
       "      <td>R1N3LBU331N1YS,R2NMV5Q9AYU4RM,R11KVGFT3HQ3AS,R...</td>\n",
       "      <td>Far better then expected,Dual Connectivity Not...</td>\n",
       "      <td>Well I had a notion that cheap bt headphones c...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41-U6BdQrc...</td>\n",
       "      <td>https://www.amazon.in/Infinity-Glide-510-Headp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>B078WB1VWJ</td>\n",
       "      <td>Usha EI 3710 Heavy Weight 1000-Watt Dry Iron w...</td>\n",
       "      <td>Home&amp;Kitchen|Kitchen&amp;HomeAppliances|Vacuum,Cle...</td>\n",
       "      <td>₹1,110</td>\n",
       "      <td>₹1,599</td>\n",
       "      <td>31%</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4,022</td>\n",
       "      <td>1.75kg heavy weight iron for better ironing;5 ...</td>\n",
       "      <td>AG4KXXU3X2W7U5GHPFTQUH7B74QQ,AGVNR5BV6PXJKH2OX...</td>\n",
       "      <td>Gyani baba,Sunil,Sakethram,Nagarajunuti,Nitin,...</td>\n",
       "      <td>R13VHF78WR3N1Z,R342QNGEZ7OI7F,R2ZL6XILY5JIM6,R...</td>\n",
       "      <td>It doesn't heat up,Value fir money,Ok,satisfie...</td>\n",
       "      <td>If y want to use it for light clothes line sil...</td>\n",
       "      <td>https://m.media-amazon.com/images/W/WEBP_40237...</td>\n",
       "      <td>https://www.amazon.in/Usha-Electric-EI3710-100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>B01LONQBDG</td>\n",
       "      <td>AmazonBasics USB Type-C to Micro-B 2.0 Cable -...</td>\n",
       "      <td>Computers&amp;Accessories|Accessories&amp;Peripherals|...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>₹899</td>\n",
       "      <td>61%</td>\n",
       "      <td>4.1</td>\n",
       "      <td>14,896</td>\n",
       "      <td>Connect a computer with a Type-C USB port (Mac...</td>\n",
       "      <td>AH42ECAG6LPCU22T5BYN5OXQO74A,AEW6XI52IO3H37U4W...</td>\n",
       "      <td>SOURAV DAS,GISHU,Bikkee Bakchi,David Gomes,pra...</td>\n",
       "      <td>RKU0YNFBI9H6U,R1L56U9MGEY65D,R1RTAR9ZHEKJKA,RZ...</td>\n",
       "      <td>Very good.,Good one. Worth Buy.,Wonderful,Amaz...</td>\n",
       "      <td>Go for it with out second thought.,It works we...</td>\n",
       "      <td>https://m.media-amazon.com/images/W/WEBP_40237...</td>\n",
       "      <td>https://www.amazon.in/AmazonBasics-USB-Type-C-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id                                       product_name  \\\n",
       "883   B0873L7J6X  Infinity (JBL Glide 510, 72 Hrs Playtime with ...   \n",
       "1387  B078WB1VWJ  Usha EI 3710 Heavy Weight 1000-Watt Dry Iron w...   \n",
       "294   B01LONQBDG  AmazonBasics USB Type-C to Micro-B 2.0 Cable -...   \n",
       "\n",
       "                                               category discounted_price  \\\n",
       "883   Electronics|Headphones,Earbuds&Accessories|Hea...           ₹1,499   \n",
       "1387  Home&Kitchen|Kitchen&HomeAppliances|Vacuum,Cle...           ₹1,110   \n",
       "294   Computers&Accessories|Accessories&Peripherals|...             ₹349   \n",
       "\n",
       "     actual_price discount_percentage rating rating_count  \\\n",
       "883        ₹3,999                 63%    4.2       42,775   \n",
       "1387       ₹1,599                 31%    4.3        4,022   \n",
       "294          ₹899                 61%    4.1       14,896   \n",
       "\n",
       "                                          about_product  \\\n",
       "883   72 Hours Playtime Under Optimum Audio Settings...   \n",
       "1387  1.75kg heavy weight iron for better ironing;5 ...   \n",
       "294   Connect a computer with a Type-C USB port (Mac...   \n",
       "\n",
       "                                                user_id  \\\n",
       "883   AGHTZ6M45GWLTAEPAMM6IEH2BXOA,AGVTW4CSK4PNN4WGW...   \n",
       "1387  AG4KXXU3X2W7U5GHPFTQUH7B74QQ,AGVNR5BV6PXJKH2OX...   \n",
       "294   AH42ECAG6LPCU22T5BYN5OXQO74A,AEW6XI52IO3H37U4W...   \n",
       "\n",
       "                                              user_name  \\\n",
       "883   (sic),Harshit,Bharath N,Pulkit Malik,Akhtar An...   \n",
       "1387  Gyani baba,Sunil,Sakethram,Nagarajunuti,Nitin,...   \n",
       "294   SOURAV DAS,GISHU,Bikkee Bakchi,David Gomes,pra...   \n",
       "\n",
       "                                              review_id  \\\n",
       "883   R1N3LBU331N1YS,R2NMV5Q9AYU4RM,R11KVGFT3HQ3AS,R...   \n",
       "1387  R13VHF78WR3N1Z,R342QNGEZ7OI7F,R2ZL6XILY5JIM6,R...   \n",
       "294   RKU0YNFBI9H6U,R1L56U9MGEY65D,R1RTAR9ZHEKJKA,RZ...   \n",
       "\n",
       "                                           review_title  \\\n",
       "883   Far better then expected,Dual Connectivity Not...   \n",
       "1387  It doesn't heat up,Value fir money,Ok,satisfie...   \n",
       "294   Very good.,Good one. Worth Buy.,Wonderful,Amaz...   \n",
       "\n",
       "                                         review_content  \\\n",
       "883   Well I had a notion that cheap bt headphones c...   \n",
       "1387  If y want to use it for light clothes line sil...   \n",
       "294   Go for it with out second thought.,It works we...   \n",
       "\n",
       "                                               img_link  \\\n",
       "883   https://m.media-amazon.com/images/I/41-U6BdQrc...   \n",
       "1387  https://m.media-amazon.com/images/W/WEBP_40237...   \n",
       "294   https://m.media-amazon.com/images/W/WEBP_40237...   \n",
       "\n",
       "                                           product_link  \n",
       "883   https://www.amazon.in/Infinity-Glide-510-Headp...  \n",
       "1387  https://www.amazon.in/Usha-Electric-EI3710-100...  \n",
       "294   https://www.amazon.in/AmazonBasics-USB-Type-C-...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/amazon.csv')\n",
    "df.sample(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('amazon.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# postgresql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read from postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    database=\"database-name\", \n",
    "    user=\"database-username\", \n",
    "    password=\"database-password\", \n",
    "    host=\"database-host\", \n",
    "    port=\"database-port\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select * from table_name\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, conn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write df to postgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import psycopg2.extras as extras\n",
    "import pandas as pd\n",
    "  \n",
    "  \n",
    "def execute_values(conn, df, table):\n",
    "  \n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "  \n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL query to execute\n",
    "    query = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"the dataframe is inserted\")\n",
    "    cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    database=\"database-name\", \n",
    "    user=\"database-username\", \n",
    "    password=\"database-password\", \n",
    "    host=\"database-host\", \n",
    "    port=\"database-port\")\n",
    "\n",
    "execute_values(conn, df, 'table-name')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete from postgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuple_conv_id = tuple(df['conversation_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "try:\n",
    "    connection = psycopg2.connect(\n",
    "        database=\"database-name\", \n",
    "        user=\"database-username\", \n",
    "        password=\"database-password\", \n",
    "        host=\"database-host\", \n",
    "        port=\"database-port\")\n",
    "    \n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    postgres_insert_query = f\"\"\" Delete from chat_summarize where\n",
    "                                 conversation_id in {df_tuple_conv_id}\n",
    "                                 \"\"\"\n",
    "\n",
    "    record_to_insert = (111111, 'faq_111111', 'Mohon', '[-0.00895969569683075, -0.01822381466627121, -0.026512397453188896]', 'baik', 1, True, now, now)\n",
    "    cursor.execute(postgres_insert_query)\n",
    "\n",
    "    connection.commit()\n",
    "    count = cursor.rowcount\n",
    "    print(count, \"Record deleted successfully into mobile table\")\n",
    "\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Failed to delete record into mobile table\", error)\n",
    "\n",
    "finally:\n",
    "    # closing database connection.\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mysql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(\n",
    "    database=\"database-name\", \n",
    "    user=\"database-username\", \n",
    "    password=\"database-password\", \n",
    "    host=\"database-host\", \n",
    "    port=\"database-port\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select * from table_name\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, conn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Credentials to database connection\n",
    "hostname=\"localhost\"\n",
    "dbname=\"db-name\"\n",
    "uname=\"db-user\"\n",
    "pwd=\"db-pass\"\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "\t\t\t\t.format(host=hostname, db=dbname, user=uname, pw=pwd))\n",
    "\n",
    "# Convert dataframe to sql table                                   \n",
    "df.to_sql('table-name', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sqlalchemy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "pymysql.install_as_MySQLdb()\n",
    "\n",
    "\n",
    "host = 'xx.xxx.xx.xxx'\n",
    "user = 'abcd'\n",
    "password = 'asdf1234'\n",
    "database = 'db-name'\n",
    "port = 1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine =  create_engine(\n",
    "        url=\"mysql+pymysql://{0}:{1}@{2}:{3}/{4}\".format(\n",
    "            user, password, host, port, database\n",
    "        )\n",
    "    )\n",
    "\n",
    "sql_df = None\n",
    "with engine.connect() as conn:\n",
    "    query = \"\"\"\n",
    "    select * from table_name\n",
    "    \"\"\"\n",
    "    sql_df = pd.read_sql(query, conn)\n",
    "    conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigquery"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read bigquery"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\"credential_project.json\")\n",
    "project_id = \"project-name\"\n",
    "client = bigquery.Client(credentials=credentials, project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_gbq\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "query = \"\"\"\n",
    "select * from dataset.table\n",
    "\"\"\"\n",
    "\n",
    "df = pandas_gbq.read_gbq(query,project_id='project-name', credentials=credentials)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"Path to your Service Account ~ JSON key\"\n",
    "client = bigquery.Client()         # Start the BigQuery Client\n",
    "# Input your Query Syntax here; You may try it first at https://console.cloud.google.com/bigquery\n",
    "QUERY = (\n",
    "    'SELECT * FROM `bigquery-public-data.covid19_nyt.us_counties` ' \n",
    "    'ORDER BY date DESC,confirmed_cases DESC '\n",
    "    'LIMIT 20')\n",
    "query_job = client.query(QUERY)    # Start Query API Request\n",
    "query_result = query_job.result()  # Get Query Result\n",
    "df = query_result.to_dataframe()   # Save the Query Resultto Dataframe\n",
    "# ---------------------------------------------\n",
    "# ---- Continue Data Analysis with your DF ----\n",
    "# ---------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_gbq.to_gbq(df, destination_table='project.dataset.table',\n",
    "                  project_id=project_id,if_exists=\"append\", \n",
    "                  credentials=credentials,progress_bar=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = ['name_table']\n",
    "\n",
    "dml_statement = (\n",
    "\"\"\"\n",
    "delete from `project.dataset.table`\n",
    "--where cast(tahun as int) = EXTRACT(YEAR FROM current_date())\n",
    "where cast(tahun as int) = 2022\n",
    "\"\"\")\n",
    "\n",
    "query_job = client.query(dml_statement)\n",
    "\n",
    "pandas_gbq.read_gbq(dml_statement, project_id='my_project_id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas set option"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.get_option(\"display.max_columns\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## format numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare 2 dataframe to see difference columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ada di php tidak ada di datamadrasahemis_csv\n",
    "\n",
    "s = set(df_a.columns)\n",
    "temp1 = [x for x in df_b.columns if x not in s]\n",
    "print(temp1)\n",
    "\n",
    "# ada di datamadrasahemis_csv tidak ada di php\n",
    "\n",
    "s = set(df_b.columns)\n",
    "temp2 = [x for x in df_a.columns if x not in s]\n",
    "print(temp2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check columns with some type datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include='int').columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change datetime to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.select_dtypes('datetime64').columns:\n",
    "    df[i] = df[i].dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if pd.api.types.is_datetime64_any_dtype(df[column]):\n",
    "        df[column] = df[column].dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "209565b58a505ff4d90712c540e0a7e0c60f2874fda309f796ea191eb82c03e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
